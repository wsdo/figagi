{
	"title": "OpenAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/platforms/openai",
	"html": "Skip to main content\nü¶úÔ∏èüîó LangChain\nDocs\nUse cases\nIntegrations\nGuides\nAPI\nMore\nü¶úÔ∏èüîó\nChat\nSearch\n‚åò\nK\nProviders\nAnthropic\nAWS\nGoogle\nHugging Face\nMicrosoft\nOpenAI\nMore\nComponents\nLLMs\nChat models\nDocument loaders\nDocument transformers\nText embedding models\nVector stores\nRetrievers\nTools\nAgents and toolkits\nMemory\nCallbacks\nChat loaders\nAdapters\nStores\nProvidersOpenAI\nOpenAI\n\nAll functionality related to OpenAI\n\nOpenAI is American artificial intelligence (AI) research laboratory consisting of the non-profit OpenAI Incorporated and its for-profit subsidiary corporation OpenAI Limited Partnership. OpenAI conducts AI research with the declared intention of promoting and developing a friendly AI. OpenAI systems run on an Azure-based supercomputing platform from Microsoft.\n\nThe OpenAI API is powered by a diverse set of models with different capabilities and price points.\n\nChatGPT is the Artificial Intelligence (AI) chatbot developed by OpenAI.\n\nInstallation and Setup‚Äã\nInstall the Python SDK with\npip install openai\n\nGet an OpenAI api key and set it as an environment variable (OPENAI_API_KEY)\nIf you want to use OpenAI's tokenizer (only available for Python 3.9+), install it\npip install tiktoken\n\nLLM‚Äã\n\nSee a usage example.\n\nfrom langchain.llms import OpenAI\n\n\nIf you are using a model hosted on Azure, you should use different wrapper for that:\n\nfrom langchain.llms import AzureOpenAI\n\n\nFor a more detailed walkthrough of the Azure wrapper, see here\n\nChat model‚Äã\n\nSee a usage example.\n\nfrom langchain.chat_models import ChatOpenAI\n\n\nIf you are using a model hosted on Azure, you should use different wrapper for that:\n\nfrom langchain.llms import AzureChatOpenAI\n\n\nFor a more detailed walkthrough of the Azure wrapper, see here\n\nText Embedding Model‚Äã\n\nSee a usage example\n\nfrom langchain.embeddings import OpenAIEmbeddings\n\nTokenizer‚Äã\n\nThere are several places you can use the tiktoken tokenizer. By default, it is used to count tokens for OpenAI LLMs.\n\nYou can also use it to count tokens when splitting documents with\n\nfrom langchain.text_splitter import CharacterTextSplitter\nCharacterTextSplitter.from_tiktoken_encoder(...)\n\n\nFor a more detailed walkthrough of this, see this notebook\n\nDocument Loader‚Äã\n\nSee a usage example.\n\nfrom langchain.document_loaders.chatgpt import ChatGPTLoader\n\nRetriever‚Äã\n\nSee a usage example.\n\nfrom langchain.retrievers import ChatGPTPluginRetriever\n\nChain‚Äã\n\nSee a usage example.\n\nfrom langchain.chains import OpenAIModerationChain\n\nAdapter‚Äã\n\nSee a usage example.\n\nfrom langchain.adapters import openai as lc_openai\n\nPrevious\nMicrosoft\nNext\nActiveloop Deep Lake\nInstallation and Setup\nLLM\nChat model\nText Embedding Model\nTokenizer\nDocument Loader\nRetriever\nChain\nAdapter\nCommunity\nDiscord\nTwitter\nGitHub\nPython\nJS/TS\nMore\nHomepage\nBlog\nCopyright ¬© 2023 LangChain, Inc."
}