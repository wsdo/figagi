{
	"title": "Agents | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/agents/",
	"html": "Skip to main content\nü¶úÔ∏èüîó LangChain\nDocs\nUse cases\nIntegrations\nGuides\nAPI\nMore\nü¶úÔ∏èüîó\nChat\nSearch\n‚åò\nK\nGet started\nIntroduction\nInstallation\nQuickstart\nSecurity\nLangChain Expression Language\nGet started\nWhy use LCEL\nInterface\nHow to\nCookbook\nModules\nModel I/O\nRetrieval\nAgents\nAgent Types\nHow-to\nTools\nMore\nLangServe\nLangSmith\nModulesAgents\nAgents\n\nThe core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n\nConcepts‚Äã\n\nThere are several key components here:\n\nAgent‚Äã\n\nThis is the chain responsible for deciding what step to take next. This is powered by a language model and a prompt. The inputs to this chain are:\n\nTools: Descriptions of available tools\nUser input: The high level objective\nIntermediate steps: Any (action, tool output) pairs previously executed in order to achieve the user input\n\nThe output is the next action(s) to take or the final response to send to the user (AgentActions or AgentFinish). An action specifies a tool and the input to that tool.\n\nDifferent agents have different prompting styles for reasoning, different ways of encoding inputs, and different ways of parsing the output. For a full list of built-in agents see agent types. You can also easily build custom agents, which we show how to do in the Get started section below.\n\nTools‚Äã\n\nTools are functions that an agent can invoke. There are two important design considerations around tools:\n\nGiving the agent access to the right tools\nDescribing the tools in a way that is most helpful to the agent\n\nWithout thinking through both, you won‚Äôt be able to build a working agent. If you don‚Äôt give the agent access to a correct set of tools, it will never be able to accomplish the objectives you give it. If you don‚Äôt describe the tools well, the agent won‚Äôt know how to use them properly.\n\nLangChain provides a wide set of built-in tools, but also makes it easy to define your own (including custom descriptions). For a full list of built-in tools, see the tools integrations section\n\nToolkits‚Äã\n\nFor many common tasks, an agent will need a set of related tools. For this LangChain provides the concept of toolkits - groups of around 3-5 tools needed to accomplish specific objectives. For example, the GitHub toolkit has a tool for searching through GitHub issues, a tool for reading a file, a tool for commenting, etc.\n\nLangChain provides a wide set of toolkits to get started. For a full list of built-in toolkits, see the toolkits integrations section\n\nAgentExecutor‚Äã\n\nThe agent executor is the runtime for an agent. This is what actually calls the agent, executes the actions it chooses, passes the action outputs back to the agent, and repeats. In pseudocode, this looks roughly like:\n\nnext_action = agent.get_action(...)\nwhile next_action != AgentFinish:\n    observation = run(next_action)\n    next_action = agent.get_action(..., next_action, observation)\nreturn next_action\n\n\nWhile this may seem simple, there are several complexities this runtime handles for you, including:\n\nHandling cases where the agent selects a non-existent tool\nHandling cases where the tool errors\nHandling cases where the agent produces output that cannot be parsed into a tool invocation\nLogging and observability at all levels (agent decisions, tool calls) to stdout and/or to LangSmith.\nOther types of agent runtimes‚Äã\n\nThe AgentExecutor class is the main agent runtime supported by LangChain. However, there are other, more experimental runtimes we also support. These include:\n\nPlan-and-execute Agent\nBaby AGI\nAuto GPT\n\nYou can also always create your own custom execution logic, which we show how to do below.\n\nGet started‚Äã\n\nTo best understand the agent framework, lets build an agent from scratch using LangChain Expression Language (LCEL). We‚Äôll need to build the agent itself, define custom tools, and run the agent and tools in a custom loop. At the end we‚Äôll show how to use the standard LangChain AgentExecutor to make execution easier.\n\nSome important terminology (and schema) to know:\n\nAgentAction: This is a dataclass that represents the action an agent should take. It has a tool property (which is the name of the tool that should be invoked) and a tool_input property (the input to that tool)\nAgentFinish: This is a dataclass that signifies that the agent has finished and should return to the user. It has a return_values parameter, which is a dictionary to return. It often only has one key - output - that is a string, and so often it is just this key that is returned.\nintermediate_steps: These represent previous agent actions and corresponding outputs that are passed around. These are important to pass to future iteration so the agent knows what work it has already done. This is typed as a List[Tuple[AgentAction, Any]]. Note that observation is currently left as type Any to be maximally flexible. In practice, this is often a string.\nSetup: LangSmith‚Äã\n\nBy definition, agents take a self-determined, input-dependent sequence of steps before returning a user-facing output. This makes debugging these systems particularly tricky, and observability particularly important. LangSmith is especially useful for such cases.\n\nWhen building with LangChain, any built-in agent or custom agent built with LCEL will automatically be traced in LangSmith. And if we use the AgentExecutor, we‚Äôll get full tracing of not only the agent planning steps but also the tool inputs and outputs.\n\nTo set up LangSmith we just need set the following environment variables:\n\nexport LANGCHAIN_TRACING_V2=\"true\"\nexport LANGCHAIN_API_KEY=\"<your-api-key>\"\n\nDefine the agent‚Äã\n\nWe first need to create our agent. This is the chain responsible for determining what action to take next.\n\nIn this example, we will use OpenAI Function Calling to create this agent. This is generally the most reliable way to create agents.\n\nFor this guide, we will construct a custom agent that has access to a custom tool. We are choosing this example because for most real world use cases you will NEED to customize either the agent or the tools. We‚Äôll create a simple tool that computes the length of a word. This is useful because it‚Äôs actually something LLMs can mess up due to tokenization. We will first create it WITHOUT memory, but we will then show how to add memory in. Memory is needed to enable conversation.\n\nFirst, let‚Äôs load the language model we‚Äôre going to use to control the agent.\n\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\n\nWe can see that it struggles to count the letters in the string ‚Äúeduca‚Äù.\n\nllm.invoke(\"how many letters in the word educa?\")\n\nAIMessage(content='There are 6 letters in the word \"educa\".')\n\n\nNext, let‚Äôs define some tools to use. Let‚Äôs write a really simple Python function to calculate the length of a word that is passed in.\n\nfrom langchain.agents import tool\n\n\n@tool\ndef get_word_length(word: str) -> int:\n    \"\"\"Returns the length of a word.\"\"\"\n    return len(word)\n\n\ntools = [get_word_length]\n\n\nNow let us create the prompt. Because OpenAI Function Calling is finetuned for tool usage, we hardly need any instructions on how to reason, or how to output format. We will just have two input variables: input and agent_scratchpad. input should be a string containing the user objective. agent_scratchpad should be a sequence of messages that contains the previous agent tool invocations and the corresponding tool outputs.\n\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n        ),\n        (\"user\", \"{input}\"),\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n    ]\n)\n\n\nHow does the agent know what tools it can use? In this case we‚Äôre relying on OpenAI function calling LLMs, which take functions as a separate argument and have been specifically trained to know when to invoke those functions.\n\nTo pass in our tools to the agent, we just need to format them to the OpenAI function format and pass them to our model. (By bind-ing the functions, we‚Äôre making sure that they‚Äôre passed in each time the model is invoked.)\n\nfrom langchain.tools.render import format_tool_to_openai_function\n\nllm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n\n\nPutting those pieces together, we can now create the agent. We will import two last utility functions: a component for formatting intermediate steps (agent action, tool output pairs) to input messages that can be sent to the model, and a component for converting the output message into an agent action/agent finish.\n\nfrom langchain.agents.format_scratchpad import format_to_openai_function_messages\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n\nagent = (\n    {\n        \"input\": lambda x: x[\"input\"],\n        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n            x[\"intermediate_steps\"]\n        ),\n    }\n    | prompt\n    | llm_with_tools\n    | OpenAIFunctionsAgentOutputParser()\n)\n\n\nNow that we have our agent, let‚Äôs play around with it! Let‚Äôs pass in a simple question and empty intermediate steps and see what it returns:\n\nagent.invoke({\"input\": \"how many letters in the word educa?\", \"intermediate_steps\": []})\n\nAgentActionMessageLog(tool='get_word_length', tool_input={'word': 'educa'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'educa'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"word\": \"educa\"\\n}', 'name': 'get_word_length'}})])\n\n\nWe can see that it responds with an AgentAction to take (it‚Äôs actually an AgentActionMessageLog - a subclass of AgentAction which also tracks the full message log).\n\nIf we‚Äôve set up LangSmith, we‚Äôll see a trace that let‚Äôs us inspect the input and output to each step in the sequence: https://smith.langchain.com/public/04110122-01a8-413c-8cd0-b4df6eefa4b7/r\n\nDefine the runtime‚Äã\n\nSo this is just the first step - now we need to write a runtime for this. The simplest one is just one that continuously loops, calling the agent, then taking the action, and repeating until an AgentFinish is returned. Let‚Äôs code that up below:\n\nfrom langchain.schema.agent import AgentFinish\n\nuser_input = \"how many letters in the word educa?\"\nintermediate_steps = []\nwhile True:\n    output = agent.invoke(\n        {\n            \"input\": user_input,\n            \"intermediate_steps\": intermediate_steps,\n        }\n    )\n    if isinstance(output, AgentFinish):\n        final_result = output.return_values[\"output\"]\n        break\n    else:\n        print(f\"TOOL NAME: {output.tool}\")\n        print(f\"TOOL INPUT: {output.tool_input}\")\n        tool = {\"get_word_length\": get_word_length}[output.tool]\n        observation = tool.run(output.tool_input)\n        intermediate_steps.append((output, observation))\nprint(final_result)\n\nTOOL NAME: get_word_length\nTOOL INPUT: {'word': 'educa'}\nThere are 5 letters in the word \"educa\".\n\n\nWoo! It‚Äôs working.\n\nUsing AgentExecutor‚Äã\n\nTo simplify this a bit, we can import and use the AgentExecutor class. This bundles up all of the above and adds in error handling, early stopping, tracing, and other quality-of-life improvements that reduce safeguards you need to write.\n\nfrom langchain.agents import AgentExecutor\n\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n\nNow let‚Äôs test it out!\n\nagent_executor.invoke({\"input\": \"how many letters in the word educa?\"})\n\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `get_word_length` with `{'word': 'educa'}`\n\n\n5There are 5 letters in the word \"educa\".\n\n> Finished chain.\n\n{'input': 'how many letters in the word educa?',\n 'output': 'There are 5 letters in the word \"educa\".'}\n\n\nAnd looking at the trace, we can see that all of our agent calls and tool invocations are automatically logged: https://smith.langchain.com/public/957b7e26-bef8-4b5b-9ca3-4b4f1c96d501/r\n\nAdding memory‚Äã\n\nThis is great - we have an agent! However, this agent is stateless - it doesn‚Äôt remember anything about previous interactions. This means you can‚Äôt ask follow up questions easily. Let‚Äôs fix that by adding in memory.\n\nIn order to do this, we need to do two things:\n\nAdd a place for memory variables to go in the prompt\nKeep track of the chat history\n\nFirst, let‚Äôs add a place for memory in the prompt. We do this by adding a placeholder for messages with the key \"chat_history\". Notice that we put this ABOVE the new user input (to follow the conversation flow).\n\nfrom langchain.prompts import MessagesPlaceholder\n\nMEMORY_KEY = \"chat_history\"\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n        ),\n        MessagesPlaceholder(variable_name=MEMORY_KEY),\n        (\"user\", \"{input}\"),\n        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n    ]\n)\n\n\nWe can then set up a list to track the chat history\n\nfrom langchain.schema.messages import AIMessage, HumanMessage\n\nchat_history = []\n\n\nWe can then put it all together!\n\nagent = (\n    {\n        \"input\": lambda x: x[\"input\"],\n        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n            x[\"intermediate_steps\"]\n        ),\n        \"chat_history\": lambda x: x[\"chat_history\"],\n    }\n    | prompt\n    | llm_with_tools\n    | OpenAIFunctionsAgentOutputParser()\n)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n\nWhen running, we now need to track the inputs and outputs as chat history\n\ninput1 = \"how many letters in the word educa?\"\nresult = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\nchat_history.extend(\n    [\n        HumanMessage(content=input1),\n        AIMessage(content=result[\"output\"]),\n    ]\n)\nagent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})\n\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `get_word_length` with `{'word': 'educa'}`\n\n\n5There are 5 letters in the word \"educa\".\n\n> Finished chain.\n\n\n> Entering new AgentExecutor chain...\nNo, \"educa\" is not a real word in English.\n\n> Finished chain.\n\n{'input': 'is that a real word?',\n 'chat_history': [HumanMessage(content='how many letters in the word educa?'),\n  AIMessage(content='There are 5 letters in the word \"educa\".')],\n 'output': 'No, \"educa\" is not a real word in English.'}\n\n\nHere‚Äôs the LangSmith trace: https://smith.langchain.com/public/1e1b7e07-3220-4a6c-8a1e-f04182a755b3/r\n\nNext Steps‚Äã\n\nAwesome! You‚Äôve now run your first end-to-end agent. To dive deeper, you can:\n\nCheck out all the different agent types supported\nLearn all the controls for AgentExecutor\nExplore the how-to‚Äôs of tools and all the tool integrations\nSee a full list of all the off-the-shelf toolkits we provide\nPrevious\nIndexing\nNext\nAgent Types\nConcepts\nAgent\nTools\nToolkits\nAgentExecutor\nOther types of agent runtimes\nGet started\nSetup: LangSmith\nDefine the agent\nDefine the runtime\nUsing AgentExecutor\nAdding memory\nNext Steps\nCommunity\nDiscord\nTwitter\nGitHub\nPython\nJS/TS\nMore\nHomepage\nBlog\nCopyright ¬© 2023 LangChain, Inc."
}