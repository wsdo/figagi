{
	"title": "Anthropic | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/platforms/anthropic",
	"html": "Skip to main content\nü¶úÔ∏èüîó LangChain\nDocs\nUse cases\nIntegrations\nGuides\nAPI\nMore\nü¶úÔ∏èüîó\nChat\nSearch\n‚åò\nK\nProviders\nAnthropic\nAWS\nGoogle\nHugging Face\nMicrosoft\nOpenAI\nMore\nComponents\nLLMs\nChat models\nDocument loaders\nDocument transformers\nText embedding models\nVector stores\nRetrievers\nTools\nAgents and toolkits\nMemory\nCallbacks\nChat loaders\nAdapters\nStores\nProvidersAnthropic\nAnthropic\n\nAll functionality related to Anthropic models.\n\nAnthropic is an AI safety and research company, and is the creator of Claude. This page covers all integrations between Anthropic models and LangChain.\n\nPrompting Overview‚Äã\n\nClaude is chat-based model, meaning it is trained on conversation data. However, it is a text based API, meaning it takes in single string. It expects this string to be in a particular format. This means that it is up the user to ensure that is the case. LangChain provides several utilities and helper functions to make sure prompts that you write - whether formatted as a string or as a list of messages - end up formatted correctly.\n\nSpecifically, Claude is trained to fill in text for the Assistant role as part of an ongoing dialogue between a human user (Human:) and an AI assistant (Assistant:). Prompts sent via the API must contain \\n\\nHuman: and \\n\\nAssistant: as the signals of who's speaking. The final turn must always be \\n\\nAssistant: - the input string cannot have \\n\\nHuman: as the final role.\n\nBecause Claude is chat-based but accepts a string as input, it can be treated as either a LangChain ChatModel or LLM. This means there are two wrappers in LangChain - ChatAnthropic and Anthropic. It is generally recommended to use the ChatAnthropic wrapper, and format your prompts as ChatMessages (we will show examples of this below). This is because it keeps your prompt in a general format that you can easily then also use with other models (should you want to). However, if you want more fine-grained control over the prompt, you can use the Anthropic wrapper - we will show and example of this as well. The Anthropic wrapper however is deprecated, as all functionality can be achieved in a more generic way using ChatAnthropic.\n\nPrompting Best Practices‚Äã\n\nAnthropic models have several prompting best practices compared to OpenAI models.\n\nNo System Messages\n\nAnthropic models are not trained on the concept of a \"system message\". We have worked with the Anthropic team to handle them somewhat appropriately (a Human message with an admin tag) but this is largely a hack and it is recommended that you do not use system messages.\n\nAI Messages Can Continue\n\nA completion from Claude is a continuation of the last text in the string which allows you further control over Claude's output. For example, putting words in Claude's mouth in a prompt like this:\n\n\\n\\nHuman: Tell me a joke about bears\\n\\nAssistant: What do you call a bear with no teeth?\n\nThis will return a completion like this A gummy bear! instead of a whole new assistant message with a different random bear joke.\n\nChatAnthropic‚Äã\n\nChatAnthropic is a subclass of LangChain's ChatModel, meaning it works best with ChatPromptTemplate. You can import this wrapper with the following code:\n\nfrom langchain.chat_models import ChatAnthropic\nmodel = ChatAnthropic()\n\n\nWhen working with ChatModels, it is preferred that you design your prompts as ChatPromptTemplates. Here is an example below of doing that:\n\nfrom langchain.prompts import ChatPromptTemplate\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful chatbot\"),\n    (\"human\", \"Tell me a joke about {topic}\"),\n])\n\n\nYou can then use this in a chain as follows:\n\nchain = prompt | model\nchain.invoke({\"topic\": \"bears\"})\n\n\nHow is the prompt actually being formatted under the hood? We can see that by running the following code\n\nprompt_value = prompt.format_prompt(topic=\"bears\")\nmodel.convert_prompt(prompt_value)\n\n\nThis produces the following formatted string:\n\n'\\n\\nYou are a helpful chatbot\\n\\nHuman: Tell me a joke about bears\\n\\nAssistant:'\n\n\nWe can see that under the hood LangChain is not appending any prefix/suffix to SystemMessage's. This is because Anthropic has no concept of SystemMessage. Anthropic requires all prompts to end with assistant messages. This means if the last message is not an assistant message, the suffix Assistant: will automatically be inserted.\n\nIf you decide instead to use a normal PromptTemplate (one that just works on a single string) let's take a look at what happens:\n\nfrom langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\nprompt_value = prompt.format_prompt(topic=\"bears\")\nmodel.convert_prompt(prompt_value)\n\n\nThis produces the following formatted string:\n\n'\\n\\nHuman: Tell me a joke about bears\\n\\nAssistant:'\n\n\nWe can see that it automatically adds the Human and Assistant tags. What is happening under the hood? First: the string gets converted to a single human message. This happens generically (because we are using a subclass of ChatModel). Then, similarly to the above example, an empty Assistant message is getting appended. This is Anthropic specific.\n\n[Deprecated] Anthropic‚Äã\n\nThis Anthropic wrapper is subclassed from LLM. We can import it with:\n\nfrom langchain.llms import Anthropic\nmodel = Anthropic()\n\n\nThis model class is designed to work with normal PromptTemplates. An example of that is below:\n\nprompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\nchain = prompt | model\nchain.invoke({\"topic\": \"bears\"})\n\n\nLet's see what is going on with the prompt templating under the hood!\n\nprompt_value = prompt.format_prompt(topic=\"bears\")\nmodel.convert_prompt(prompt_value)\n\n\nThis outputs the following\n\n'\\n\\nHuman: Tell me a joke about bears\\n\\nAssistant: Sure, here you go:\\n'\n\n\nNotice that it adds the Human tag at the start of the string, and then finishes it with \\n\\nAssistant: Sure, here you go:. The extra Sure, here you go was added on purpose by the Anthropic team.\n\nWhat happens if we have those symbols in the prompt directly?\n\nprompt = PromptTemplate.from_template(\"Human: Tell me a joke about {topic}\")\nprompt_value = prompt.format_prompt(topic=\"bears\")\nmodel.convert_prompt(prompt_value)\n\n\nThis outputs:\n\n'\\n\\nHuman: Tell me a joke about bears'\n\n\nWe can see that we detect that the user is trying to use the special tokens, and so we don't do any formatting.\n\nPrevious\nProviders\nNext\nAWS\nPrompting Overview\nPrompting Best Practices\nChatAnthropic\nDeprecated Anthropic\nCommunity\nDiscord\nTwitter\nGitHub\nPython\nJS/TS\nMore\nHomepage\nBlog\nCopyright ¬© 2023 LangChain, Inc."
}