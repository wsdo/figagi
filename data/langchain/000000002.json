{
	"title": "SQL | 🦜️🔗 Langchain",
	"url": "https://python.langchain.com/docs/use_cases/qa_structured/sql",
	"html": "Skip to main content\n🦜️🔗 LangChain\nDocs\nUse cases\nIntegrations\nGuides\nAPI\nMore\n🦜️🔗\nChat\nSearch\n⌘\nK\nQA over structured data\nSQL\nRetrieval-augmented generation (RAG)\nInteracting with APIs\nChatbots\nExtraction\nSummarization\nTagging\nWeb scraping\nSynthetic data generation\nGraph querying\nQA over structured dataSQL\nSQL\n\nOpen In Colab\n\nUse case​\n\nEnterprise data is often stored in SQL databases.\n\nLLMs make it possible to interact with SQL databases using natural language.\n\nLangChain offers SQL Chains and Agents to build and run SQL queries based on natural language prompts.\n\nThese are compatible with any SQL dialect supported by SQLAlchemy (e.g., MySQL, PostgreSQL, Oracle SQL, Databricks, SQLite).\n\nThey enable use cases such as:\n\nGenerating queries that will be run based on natural language questions\nCreating chatbots that can answer questions based on database data\nBuilding custom dashboards based on insights a user wants to analyze\nOverview​\n\nLangChain provides tools to interact with SQL Databases:\n\nBuild SQL queries based on natural language user questions\nQuery a SQL database using chains for query creation and execution\nInteract with a SQL database using agents for robust and flexible querying\n\nQuickstart​\n\nFirst, get required packages and set environment variables:\n\n! pip install langchain langchain-experimental openai\n\n# Set env var OPENAI_API_KEY or load from a .env file\n# import dotenv\n\n# dotenv.load_dotenv()\n\n\nThe below example will use a SQLite connection with Chinook database.\n\nFollow installation steps to create Chinook.db in the same directory as this notebook:\n\nSave this file to the directory as Chinook_Sqlite.sql\nRun sqlite3 Chinook.db\nRun .read Chinook_Sqlite.sql\nTest SELECT * FROM Artist LIMIT 10;\n\nNow, Chinhook.db is in our directory.\n\nLet’s create a SQLDatabaseChain to create and execute SQL queries.\n\nfrom langchain.llms import OpenAI\nfrom langchain.utilities import SQLDatabase\nfrom langchain_experimental.sql import SQLDatabaseChain\n\ndb = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\nllm = OpenAI(temperature=0, verbose=True)\ndb_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n\ndb_chain.run(\"How many employees are there?\")\n\n\n\n> Entering new SQLDatabaseChain chain...\nHow many employees are there?\nSQLQuery:SELECT COUNT(*) FROM \"Employee\";\nSQLResult: [(8,)]\nAnswer:There are 8 employees.\n> Finished chain.\n\n'There are 8 employees.'\n\n\nNote that this both creates and executes the query.\n\nIn the following sections, we will cover the 3 different use cases mentioned in the overview.\n\nGo deeper​\n\nYou can load tabular data from other sources other than SQL Databases. For example: - Loading a CSV file - Loading a Pandas DataFrame Here you can check full list of Document Loaders\n\nCase 1: Text-to-SQL query​\nfrom langchain.chains import create_sql_query_chain\nfrom langchain.chat_models import ChatOpenAI\n\n\nLet’s create the chain that will build the SQL Query:\n\nchain = create_sql_query_chain(ChatOpenAI(temperature=0), db)\nresponse = chain.invoke({\"question\": \"How many employees are there\"})\nprint(response)\n\nSELECT COUNT(*) FROM Employee\n\n\nAfter building the SQL query based on a user question, we can execute the query:\n\ndb.run(response)\n\n'[(8,)]'\n\n\nAs we can see, the SQL Query Builder chain only created the query, and we handled the query execution separately.\n\nGo deeper​\n\nLooking under the hood\n\nWe can look at the LangSmith trace to unpack this:\n\nSome papers have reported good performance when prompting with:\n\nA CREATE TABLE description for each table, which include column names, their types, etc\nFollowed by three example rows in a SELECT statement\n\ncreate_sql_query_chain adopts this the best practice (see more in this blog).\n\n\nImprovements\n\nThe query builder can be improved in several ways, such as (but not limited to):\n\nCustomizing database description to your specific use case\nHardcoding a few examples of questions and their corresponding SQL query in the prompt\nUsing a vector database to include dynamic examples that are relevant to the specific user question\n\nAll these examples involve customizing the chain’s prompt.\n\nFor example, we can include a few examples in our prompt like so:\n\nfrom langchain.prompts import PromptTemplate\n\nTEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\nUse the following format:\n\nQuestion: \"Question here\"\nSQLQuery: \"SQL Query to run\"\nSQLResult: \"Result of the SQLQuery\"\nAnswer: \"Final answer here\"\n\nOnly use the following tables:\n\n{table_info}.\n\nSome examples of SQL queries that correspond to questions are:\n\n{few_shot_examples}\n\nQuestion: {input}\"\"\"\n\nCUSTOM_PROMPT = PromptTemplate(\n    input_variables=[\"input\", \"few_shot_examples\", \"table_info\", \"dialect\"],\n    template=TEMPLATE,\n)\n\n\nWe can also access this prompt in the LangChain prompt hub.\n\nThis will work with your LangSmith API key.\n\nfrom langchain import hub\n\nCUSTOM_PROMPT = hub.pull(\"rlm/text-to-sql\")\n\nCase 2: Text-to-SQL query and execution​\n\nWe can use SQLDatabaseChain from langchain_experimental to create and run SQL queries.\n\nfrom langchain.llms import OpenAI\nfrom langchain_experimental.sql import SQLDatabaseChain\n\nllm = OpenAI(temperature=0, verbose=True)\ndb_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n\ndb_chain.run(\"How many employees are there?\")\n\n\n\n> Entering new SQLDatabaseChain chain...\nHow many employees are there?\nSQLQuery:SELECT COUNT(*) FROM \"Employee\";\nSQLResult: [(8,)]\nAnswer:There are 8 employees.\n> Finished chain.\n\n'There are 8 employees.'\n\n\nAs we can see, we get the same result as the previous case.\n\nHere, the chain also handles the query execution and provides a final answer based on the user question and the query result.\n\nBe careful while using this approach as it is susceptible to SQL Injection:\n\nThe chain is executing queries that are created by an LLM, and weren’t validated\ne.g. records may be created, modified or deleted unintentionally_\n\nThis is why we see the SQLDatabaseChain is inside langchain_experimental.\n\nGo deeper​\n\nLooking under the hood\n\nWe can use the LangSmith trace to see what is happening under the hood:\n\nAs discussed above, first we create the query:\ntext: ' SELECT COUNT(*) FROM \"Employee\";'\n\nThen, it executes the query and passes the results to an LLM for synthesis.\n\nImprovements\n\nThe performance of the SQLDatabaseChain can be enhanced in several ways:\n\nAdding sample rows\nSpecifying custom table information\nUsing Query Checker self-correct invalid SQL using parameter use_query_checker=True\nCustomizing the LLM Prompt include specific instructions or relevant information, using parameter prompt=CUSTOM_PROMPT\nGet intermediate steps access the SQL statement as well as the final result using parameter return_intermediate_steps=True\nLimit the number of rows a query will return using parameter top_k=5\n\nYou might find SQLDatabaseSequentialChain useful for cases in which the number of tables in the database is large.\n\nThis Sequential Chain handles the process of:\n\nDetermining which tables to use based on the user question\nCalling the normal SQL database chain using only relevant tables\n\nAdding Sample Rows\n\nProviding sample data can help the LLM construct correct queries when the data format is not obvious.\n\nFor example, we can tell LLM that artists are saved with their full names by providing two rows from the Track table.\n\ndb = SQLDatabase.from_uri(\n    \"sqlite:///Chinook.db\",\n    include_tables=[\n        \"Track\"\n    ],  # we include only one table to save tokens in the prompt :)\n    sample_rows_in_table_info=2,\n)\n\n\nThe sample rows are added to the prompt after each corresponding table’s column information.\n\nWe can use db.table_info and check which sample rows are included:\n\nprint(db.table_info)\n\n\nCREATE TABLE \"Track\" (\n    \"TrackId\" INTEGER NOT NULL, \n    \"Name\" NVARCHAR(200) NOT NULL, \n    \"AlbumId\" INTEGER, \n    \"MediaTypeId\" INTEGER NOT NULL, \n    \"GenreId\" INTEGER, \n    \"Composer\" NVARCHAR(220), \n    \"Milliseconds\" INTEGER NOT NULL, \n    \"Bytes\" INTEGER, \n    \"UnitPrice\" NUMERIC(10, 2) NOT NULL, \n    PRIMARY KEY (\"TrackId\"), \n    FOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \n    FOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \n    FOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\n)\n\n/*\n2 rows from Track table:\nTrackId Name    AlbumId MediaTypeId GenreId Composer    Milliseconds    Bytes   UnitPrice\n1   For Those About To Rock (We Salute You) 1   1   1   Angus Young, Malcolm Young, Brian Johnson   343719  11170334    0.99\n2   Balls to the Wall   2   2   1   None    342562  5510424 0.99\n*/\n\nCase 3: SQL agents​\n\nLangChain has an SQL Agent which provides a more flexible way of interacting with SQL Databases than the SQLDatabaseChain.\n\nThe main advantages of using the SQL Agent are:\n\nIt can answer questions based on the databases’ schema as well as on the databases’ content (like describing a specific table)\nIt can recover from errors by running a generated query, catching the traceback and regenerating it correctly\n\nTo initialize the agent, we use create_sql_agent function.\n\nThis agent contains the SQLDatabaseToolkit which contains tools to:\n\nCreate and execute queries\nCheck query syntax\nRetrieve table descriptions\n… and more\nfrom langchain.agents import create_sql_agent\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\n\n# from langchain.agents import AgentExecutor\nfrom langchain.agents.agent_types import AgentType\n\ndb = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n\nagent_executor = create_sql_agent(\n    llm=OpenAI(temperature=0),\n    toolkit=SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0)),\n    verbose=True,\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n)\n\nAgent task example #1 - Running queries​\nagent_executor.run(\n    \"List the total sales per country. Which country's customers spent the most?\"\n)\n\n\n\n> Entering new AgentExecutor chain...\nAction: sql_db_list_tables\nAction Input: \nObservation: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\nThought: I should query the schema of the Invoice and Customer tables.\nAction: sql_db_schema\nAction Input: Invoice, Customer\nObservation: \nCREATE TABLE \"Customer\" (\n    \"CustomerId\" INTEGER NOT NULL, \n    \"FirstName\" NVARCHAR(40) NOT NULL, \n    \"LastName\" NVARCHAR(20) NOT NULL, \n    \"Company\" NVARCHAR(80), \n    \"Address\" NVARCHAR(70), \n    \"City\" NVARCHAR(40), \n    \"State\" NVARCHAR(40), \n    \"Country\" NVARCHAR(40), \n    \"PostalCode\" NVARCHAR(10), \n    \"Phone\" NVARCHAR(24), \n    \"Fax\" NVARCHAR(24), \n    \"Email\" NVARCHAR(60) NOT NULL, \n    \"SupportRepId\" INTEGER, \n    PRIMARY KEY (\"CustomerId\"), \n    FOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n)\n\n/*\n3 rows from Customer table:\nCustomerId  FirstName   LastName    Company Address City    State   Country PostalCode  Phone   Fax Email   SupportRepId\n1   Luís    Gonçalves   Embraer - Empresa Brasileira de Aeronáutica S.A.    Av. Brigadeiro Faria Lima, 2170 São José dos Campos SP  Brazil  12227-000   +55 (12) 3923-5555  +55 (12) 3923-5566  luisg@embraer.com.br    3\n2   Leonie  Köhler  None    Theodor-Heuss-Straße 34 Stuttgart   None    Germany 70174   +49 0711 2842222    None    leonekohler@surfeu.de   5\n3   François    Tremblay    None    1498 rue Bélanger   Montréal    QC  Canada  H2G 1A7 +1 (514) 721-4711   None    ftremblay@gmail.com 3\n*/\n\n\nCREATE TABLE \"Invoice\" (\n    \"InvoiceId\" INTEGER NOT NULL, \n    \"CustomerId\" INTEGER NOT NULL, \n    \"InvoiceDate\" DATETIME NOT NULL, \n    \"BillingAddress\" NVARCHAR(70), \n    \"BillingCity\" NVARCHAR(40), \n    \"BillingState\" NVARCHAR(40), \n    \"BillingCountry\" NVARCHAR(40), \n    \"BillingPostalCode\" NVARCHAR(10), \n    \"Total\" NUMERIC(10, 2) NOT NULL, \n    PRIMARY KEY (\"InvoiceId\"), \n    FOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n)\n\n/*\n3 rows from Invoice table:\nInvoiceId   CustomerId  InvoiceDate BillingAddress  BillingCity BillingState    BillingCountry  BillingPostalCode   Total\n1   2   2009-01-01 00:00:00 Theodor-Heuss-Straße 34 Stuttgart   None    Germany 70174   1.98\n2   4   2009-01-02 00:00:00 Ullevålsveien 14    Oslo    None    Norway  0171    3.96\n3   8   2009-01-03 00:00:00 Grétrystraat 63 Brussels    None    Belgium 1000    5.94\n*/\nThought: I should query the total sales per country.\nAction: sql_db_query\nAction Input: SELECT Country, SUM(Total) AS TotalSales FROM Invoice INNER JOIN Customer ON Invoice.CustomerId = Customer.CustomerId GROUP BY Country ORDER BY TotalSales DESC LIMIT 10\nObservation: [('USA', 523.0600000000003), ('Canada', 303.9599999999999), ('France', 195.09999999999994), ('Brazil', 190.09999999999997), ('Germany', 156.48), ('United Kingdom', 112.85999999999999), ('Czech Republic', 90.24000000000001), ('Portugal', 77.23999999999998), ('India', 75.25999999999999), ('Chile', 46.62)]\nThought: I now know the final answer\nFinal Answer: The country with the highest total sales is the USA, with a total of $523.06.\n\n> Finished chain.\n\n'The country with the highest total sales is the USA, with a total of $523.06.'\n\n\nLooking at the LangSmith trace, we can see:\n\nThe agent is using a ReAct style prompt\nFirst, it will look at the tables: Action: sql_db_list_tables using tool sql_db_list_tables\nGiven the tables as an observation, it thinks and then determinates the next action:\nObservation: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\nThought: I should query the schema of the Invoice and Customer tables.\nAction: sql_db_schema\nAction Input: Invoice, Customer\n\nIt then formulates the query using the schema from tool sql_db_schema\nThought: I should query the total sales per country.\nAction: sql_db_query\nAction Input: SELECT Country, SUM(Total) AS TotalSales FROM Invoice INNER JOIN Customer ON Invoice.CustomerId = Customer.CustomerId GROUP BY Country ORDER BY TotalSales DESC LIMIT 10\n\nIt finally executes the generated query using tool sql_db_query\n\nAgent task example #2 - Describing a Table​\nagent_executor.run(\"Describe the playlisttrack table\")\n\n\n\n> Entering new AgentExecutor chain...\nAction: sql_db_list_tables\nAction Input: \nObservation: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\nThought: The PlaylistTrack table is the most relevant to the question.\nAction: sql_db_schema\nAction Input: PlaylistTrack\nObservation: \nCREATE TABLE \"PlaylistTrack\" (\n    \"PlaylistId\" INTEGER NOT NULL, \n    \"TrackId\" INTEGER NOT NULL, \n    PRIMARY KEY (\"PlaylistId\", \"TrackId\"), \n    FOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \n    FOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\n)\n\n/*\n3 rows from PlaylistTrack table:\nPlaylistId  TrackId\n1   3402\n1   3389\n1   3390\n*/\nThought: I now know the final answer\nFinal Answer: The PlaylistTrack table contains two columns, PlaylistId and TrackId, which are both integers and form a primary key. It also has two foreign keys, one to the Track table and one to the Playlist table.\n\n> Finished chain.\n\n'The PlaylistTrack table contains two columns, PlaylistId and TrackId, which are both integers and form a primary key. It also has two foreign keys, one to the Track table and one to the Playlist table.'\n\nExtending the SQL Toolkit​\n\nAlthough the out-of-the-box SQL Toolkit contains the necessary tools to start working on a database, it is often the case that some extra tools may be useful for extending the agent’s capabilities. This is particularly useful when trying to use domain specific knowledge in the solution, in order to improve its overall performance.\n\nSome examples include:\n\nIncluding dynamic few shot examples\nFinding misspellings in proper nouns to use as column filters\n\nWe can create separate tools which tackle these specific use cases and include them as a complement to the standard SQL Toolkit. Let’s see how to include these two custom tools.\n\nIncluding dynamic few-shot examples​\n\nIn order to include dynamic few-shot examples, we need a custom Retriever Tool that handles the vector database in order to retrieve the examples that are semantically similar to the user’s question.\n\nLet’s start by creating a dictionary with some examples:\n\nfew_shots = {\n    \"List all artists.\": \"SELECT * FROM artists;\",\n    \"Find all albums for the artist 'AC/DC'.\": \"SELECT * FROM albums WHERE ArtistId = (SELECT ArtistId FROM artists WHERE Name = 'AC/DC');\",\n    \"List all tracks in the 'Rock' genre.\": \"SELECT * FROM tracks WHERE GenreId = (SELECT GenreId FROM genres WHERE Name = 'Rock');\",\n    \"Find the total duration of all tracks.\": \"SELECT SUM(Milliseconds) FROM tracks;\",\n    \"List all customers from Canada.\": \"SELECT * FROM customers WHERE Country = 'Canada';\",\n    \"How many tracks are there in the album with ID 5?\": \"SELECT COUNT(*) FROM tracks WHERE AlbumId = 5;\",\n    \"Find the total number of invoices.\": \"SELECT COUNT(*) FROM invoices;\",\n    \"List all tracks that are longer than 5 minutes.\": \"SELECT * FROM tracks WHERE Milliseconds > 300000;\",\n    \"Who are the top 5 customers by total purchase?\": \"SELECT CustomerId, SUM(Total) AS TotalPurchase FROM invoices GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5;\",\n    \"Which albums are from the year 2000?\": \"SELECT * FROM albums WHERE strftime('%Y', ReleaseDate) = '2000';\",\n    \"How many employees are there\": 'SELECT COUNT(*) FROM \"employee\"',\n}\n\n\nWe can then create a retriever using the list of questions, assigning the target SQL query as metadata:\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.schema import Document\nfrom langchain.vectorstores import FAISS\n\nembeddings = OpenAIEmbeddings()\n\nfew_shot_docs = [\n    Document(page_content=question, metadata={\"sql_query\": few_shots[question]})\n    for question in few_shots.keys()\n]\nvector_db = FAISS.from_documents(few_shot_docs, embeddings)\nretriever = vector_db.as_retriever()\n\n\nNow we can create our own custom tool and append it as a new tool in the create_sql_agent function:\n\nfrom langchain.agents.agent_toolkits import create_retriever_tool\n\ntool_description = \"\"\"\nThis tool will help you understand similar examples to adapt them to the user question.\nInput to this tool should be the user question.\n\"\"\"\n\nretriever_tool = create_retriever_tool(\n    retriever, name=\"sql_get_similar_examples\", description=tool_description\n)\ncustom_tool_list = [retriever_tool]\n\n\nNow we can create the agent, adjusting the standard SQL Agent suffix to consider our use case. Although the most straightforward way to handle this would be to include it just in the tool description, this is often not enough and we need to specify it in the agent prompt using the suffix argument in the constructor.\n\nfrom langchain.agents import AgentType, create_sql_agent\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.utilities import SQLDatabase\n\ndb = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\nllm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)\n\ncustom_suffix = \"\"\"\nI should first get the similar examples I know.\nIf the examples are enough to construct the query, I can build it.\nOtherwise, I can then look at the tables in the database to see what I can query.\nThen I should query the schema of the most relevant tables\n\"\"\"\n\nagent = create_sql_agent(\n    llm=llm,\n    toolkit=toolkit,\n    verbose=True,\n    agent_type=AgentType.OPENAI_FUNCTIONS,\n    extra_tools=custom_tool_list,\n    suffix=custom_suffix,\n)\n\n\nLet’s try it out:\n\nagent.run(\"How many employees do we have?\")\n\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `sql_get_similar_examples` with `How many employees do we have?`\n\n\n[Document(page_content='How many employees are there', metadata={'sql_query': 'SELECT COUNT(*) FROM \"employee\"'}), Document(page_content='Find the total number of invoices.', metadata={'sql_query': 'SELECT COUNT(*) FROM invoices;'})]\nInvoking: `sql_db_query_checker` with `SELECT COUNT(*) FROM employee`\nresponded: {content}\n\nSELECT COUNT(*) FROM employee\nInvoking: `sql_db_query` with `SELECT COUNT(*) FROM employee`\n\n\n[(8,)]We have 8 employees.\n\n> Finished chain.\n\n'We have 8 employees.'\n\n\nAs we can see, the agent first used the sql_get_similar_examples tool in order to retrieve similar examples. As the question was very similar to other few shot examples, the agent didn’t need to use any other tool from the standard Toolkit, thus saving time and tokens.\n\nFinding and correcting misspellings for proper nouns​\n\nIn order to filter columns that contain proper nouns such as addresses, song names or artists, we first need to double-check the spelling in order to filter the data correctly.\n\nWe can achieve this by creating a vector store using all the distinct proper nouns that exist in the database. We can then have the agent query that vector store each time the user includes a proper noun in their question, to find the correct spelling for that word. In this way, the agent can make sure it understands which entity the user is referring to before building the target query.\n\nLet’s follow a similar approach to the few shots, but without metadata: just embedding the proper nouns and then querying to get the most similar one to the misspelled user question.\n\nFirst we need the unique values for each entity we want, for which we define a function that parses the result into a list of elements:\n\nimport ast\nimport re\n\n\ndef run_query_save_results(db, query):\n    res = db.run(query)\n    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n    return res\n\n\nartists = run_query_save_results(db, \"SELECT Name FROM Artist\")\nalbums = run_query_save_results(db, \"SELECT Title FROM Album\")\n\n\nNow we can proceed with creating the custom retriever tool and the final agent:\n\nfrom langchain.agents.agent_toolkits import create_retriever_tool\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\n\ntexts = artists + albums\n\nembeddings = OpenAIEmbeddings()\nvector_db = FAISS.from_texts(texts, embeddings)\nretriever = vector_db.as_retriever()\n\nretriever_tool = create_retriever_tool(\n    retriever,\n    name=\"name_search\",\n    description=\"use to learn how a piece of data is actually written, can be from names, surnames addresses etc\",\n)\n\ncustom_tool_list = [retriever_tool]\n\nfrom langchain.agents import AgentType, create_sql_agent\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.utilities import SQLDatabase\n\n# db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\nllm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)\n\ncustom_suffix = \"\"\"\nIf a user asks for me to filter based on proper nouns, I should first check the spelling using the name_search tool.\nOtherwise, I can then look at the tables in the database to see what I can query.\nThen I should query the schema of the most relevant tables\n\"\"\"\n\nagent = create_sql_agent(\n    llm=llm,\n    toolkit=toolkit,\n    verbose=True,\n    agent_type=AgentType.OPENAI_FUNCTIONS,\n    extra_tools=custom_tool_list,\n    suffix=custom_suffix,\n)\n\n\nLet’s try it out:\n\nagent.run(\"How many albums does alis in pains have?\")\n\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `name_search` with `alis in pains`\n\n\n[Document(page_content='House of Pain', metadata={}), Document(page_content='Alice In Chains', metadata={}), Document(page_content='Aisha Duo', metadata={}), Document(page_content='House Of Pain', metadata={})]\nInvoking: `sql_db_list_tables` with ``\nresponded: {content}\n\nAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\nInvoking: `sql_db_schema` with `Album, Artist`\nresponded: {content}\n\n\nCREATE TABLE \"Album\" (\n    \"AlbumId\" INTEGER NOT NULL, \n    \"Title\" NVARCHAR(160) NOT NULL, \n    \"ArtistId\" INTEGER NOT NULL, \n    PRIMARY KEY (\"AlbumId\"), \n    FOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\n)\n\n/*\n3 rows from Album table:\nAlbumId Title   ArtistId\n1   For Those About To Rock We Salute You   1\n2   Balls to the Wall   2\n3   Restless and Wild   2\n*/\n\n\nCREATE TABLE \"Artist\" (\n    \"ArtistId\" INTEGER NOT NULL, \n    \"Name\" NVARCHAR(120), \n    PRIMARY KEY (\"ArtistId\")\n)\n\n/*\n3 rows from Artist table:\nArtistId    Name\n1   AC/DC\n2   Accept\n3   Aerosmith\n*/\nInvoking: `sql_db_query_checker` with `SELECT COUNT(*) FROM Album JOIN Artist ON Album.ArtistId = Artist.ArtistId WHERE Artist.Name = 'Alice In Chains'`\nresponded: {content}\n\nSELECT COUNT(*) FROM Album JOIN Artist ON Album.ArtistId = Artist.ArtistId WHERE Artist.Name = 'Alice In Chains'\nInvoking: `sql_db_query` with `SELECT COUNT(*) FROM Album JOIN Artist ON Album.ArtistId = Artist.ArtistId WHERE Artist.Name = 'Alice In Chains'`\n\n\n[(1,)]Alice In Chains has 1 album in the database.\n\n> Finished chain.\n\n'Alice In Chains has 1 album in the database.'\n\n\nAs we can see, the agent used the name_search tool in order to check how to correctly query the database for this specific artist.\n\nGo deeper​\n\nTo learn more about the SQL Agent and how it works we refer to the SQL Agent Toolkit documentation.\n\nYou can also check Agents for other document types: - Pandas Agent - CSV Agent\n\nElastic Search​\n\nGoing beyond the above use-case, there are integrations with other databases.\n\nFor example, we can interact with Elasticsearch analytics database.\n\nThis chain builds search queries via the Elasticsearch DSL API (filters and aggregations).\n\nThe Elasticsearch client must have permissions for index listing, mapping description and search queries.\n\nSee here for instructions on how to run Elasticsearch locally.\n\nMake sure to install the Elasticsearch Python client before:\n\npip install elasticsearch\n\nfrom elasticsearch import Elasticsearch\nfrom langchain.chains.elasticsearch_database import ElasticsearchDatabaseChain\nfrom langchain.chat_models import ChatOpenAI\n\n# Initialize Elasticsearch python client.\n# See https://elasticsearch-py.readthedocs.io/en/v8.8.2/api.html#elasticsearch.Elasticsearch\nELASTIC_SEARCH_SERVER = \"https://elastic:pass@localhost:9200\"\ndb = Elasticsearch(ELASTIC_SEARCH_SERVER)\n\n\nUncomment the next cell to initially populate your db.\n\n# customers = [\n#     {\"firstname\": \"Jennifer\", \"lastname\": \"Walters\"},\n#     {\"firstname\": \"Monica\",\"lastname\":\"Rambeau\"},\n#     {\"firstname\": \"Carol\",\"lastname\":\"Danvers\"},\n#     {\"firstname\": \"Wanda\",\"lastname\":\"Maximoff\"},\n#     {\"firstname\": \"Jennifer\",\"lastname\":\"Takeda\"},\n# ]\n# for i, customer in enumerate(customers):\n#     db.create(index=\"customers\", document=customer, id=i)\n\nllm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\nchain = ElasticsearchDatabaseChain.from_llm(llm=llm, database=db, verbose=True)\n\nquestion = \"What are the first names of all the customers?\"\nchain.run(question)\n\n\nWe can customize the prompt.\n\nfrom langchain.prompts.prompt import PromptTemplate\n\nPROMPT_TEMPLATE = \"\"\"Given an input question, create a syntactically correct Elasticsearch query to run. Unless the user specifies in their question a specific number of examples they wish to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n\nUnless told to do not query for all the columns from a specific index, only ask for a the few relevant columns given the question.\n\nPay attention to use only the column names that you can see in the mapping description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which index. Return the query as valid json.\n\nUse the following format:\n\nQuestion: Question here\nESQuery: Elasticsearch Query formatted as json\n\"\"\"\n\nPROMPT = PromptTemplate.from_template(\n    PROMPT_TEMPLATE,\n)\nchain = ElasticsearchDatabaseChain.from_llm(llm=llm, database=db, query_prompt=PROMPT)\n\nNext\nRetrieval-augmented generation (RAG)\nUse case\nOverview\nQuickstart\nGo deeper\nCase 1: Text-to-SQL query\nGo deeper\nCase 2: Text-to-SQL query and execution\nGo deeper\nCase 3: SQL agents\nAgent task example #1 - Running queries\nAgent task example #2 - Describing a Table\nExtending the SQL Toolkit\nGo deeper\nElastic Search\nCommunity\nDiscord\nTwitter\nGitHub\nPython\nJS/TS\nMore\nHomepage\nBlog\nCopyright © 2023 LangChain, Inc."
}