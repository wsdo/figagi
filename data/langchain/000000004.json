{
	"title": "Debugging | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/guides/debugging",
	"html": "Skip to main content\nü¶úÔ∏èüîó LangChain\nDocs\nUse cases\nIntegrations\nGuides\nAPI\nMore\nü¶úÔ∏èüîó\nChat\nSearch\n‚åò\nK\nDebugging\nDeployment\nEvaluation\nFallbacks\nRun LLMs locally\nModel comparison\nPrivacy\nPydantic compatibility\nSafety\nDebugging\nDebugging\n\nIf you're building with LLMs, at some point something will break, and you'll need to debug. A model call will fail, or the model output will be misformatted, or there will be some nested model calls and it won't be clear where along the way an incorrect output was created.\n\nHere are a few different tools and functionalities to aid in debugging.\n\nTracing‚Äã\n\nPlatforms with tracing capabilities like LangSmith and WandB are the most comprehensive solutions for debugging. These platforms make it easy to not only log and visualize LLM apps, but also to actively debug, test and refine them.\n\nFor anyone building production-grade LLM applications, we highly recommend using a platform like this.\n\nset_debug and set_verbose‚Äã\n\nIf you're prototyping in Jupyter Notebooks or running Python scripts, it can be helpful to print out the intermediate steps of a Chain run.\n\nThere are a number of ways to enable printing at varying degrees of verbosity.\n\nLet's suppose we have a simple agent, and want to visualize the actions it takes and tool outputs it receives. Without any debugging, here's what we see:\n\nfrom langchain.agents import AgentType, initialize_agent, load_tools\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\ntools = load_tools([\"ddg-search\", \"llm-math\"], llm=llm)\nagent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n\nagent.run(\"Who directed the 2023 film Oppenheimer and what is their age? What is their age in days (assume 365 days per year)?\")\n\n    'The director of the 2023 film Oppenheimer is Christopher Nolan and he is approximately 19345 days old in 2023.'\n\nset_debug(True)‚Äã\n\nSetting the global debug flag will cause all LangChain components with callback support (chains, models, agents, tools, retrievers) to print the inputs they receive and outputs they generate. This is the most verbose setting and will fully log raw inputs and outputs.\n\nfrom langchain.globals import set_debug\n\nset_debug(True)\n\nagent.run(\"Who directed the 2023 film Oppenheimer and what is their age? What is their age in days (assume 365 days per year)?\")\n\nConsole output\nset_verbose(True)‚Äã\n\nSetting the verbose flag will print out inputs and outputs in a slightly more readable format and will skip logging certain raw outputs (like the token usage stats for an LLM call) so that you can focus on application logic.\n\nfrom langchain.globals import set_verbose\n\nset_verbose(True)\n\nagent.run(\"Who directed the 2023 film Oppenheimer and what is their age? What is their age in days (assume 365 days per year)?\")\n\nConsole output\nChain(..., verbose=True)‚Äã\n\nYou can also scope verbosity down to a single object, in which case only the inputs and outputs to that object are printed (along with any additional callbacks calls made specifically by that object).\n\n# Passing verbose=True to initialize_agent will pass that along to the AgentExecutor (which is a Chain).\nagent = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n\nagent.run(\"Who directed the 2023 film Oppenheimer and what is their age? What is their age in days (assume 365 days per year)?\")\n\nConsole output\nOther callbacks‚Äã\n\nCallbacks are what we use to execute any functionality within a component outside the primary component logic. All of the above solutions use Callbacks under the hood to log intermediate steps of components. There are a number of Callbacks relevant for debugging that come with LangChain out of the box, like the FileCallbackHandler. You can also implement your own callbacks to execute custom functionality.\n\nSee here for more info on Callbacks, how to use them, and customize them.\n\nNext\nDeployment\nTracing\nset_debug and set_verbose\nset_debug(True)\nset_verbose(True)\nChain(..., verbose=True)\nOther callbacks\nCommunity\nDiscord\nTwitter\nGitHub\nPython\nJS/TS\nMore\nHomepage\nBlog\nCopyright ¬© 2023 LangChain, Inc."
}